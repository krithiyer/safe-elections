{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs294s_1A_QQP_finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMjZvmgdfbNQgLCnARyiigP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krithiyer/safe-elections/blob/main/cs294s_1A_QQP_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_r4SzLVFc3",
        "outputId": "c35e6cbe-f592-4e29-f821-55fc701f4b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL3CtFjHVQe1"
      },
      "source": [
        "train.csv (training data from Quora Duplicate questions dataset is replicated in local drive at cs294s dir). The same dir also used for saving fine-tuned models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiaKR3wmVZ2b",
        "outputId": "564cd3eb-b99b-4220-e8d6-6648ceef2714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/cs294s/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/cs294s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88IaJM4SVqs5"
      },
      "source": [
        "Step 1: Fine tuning on Quora Question Pair Dataset\n",
        "More information on the dataset available at\n",
        "\n",
        "https://www.kaggle.com/c/quora-question-pairs\n",
        "\n",
        "Using pandas to read the question dataset and exploring the dataset a bit - reading only 5K question pairs for the initial explroation\n",
        "\n",
        "QQ pair dataset has 404,290 questions in the training set and 2,345,795 questions in the test set.\n",
        "\n",
        "Note: 3 questions in the dataset contain NaN values. This causes problems during downstream model training. The 3 question paris with NaN values are removed from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf6J3PLVVp-6",
        "outputId": "d048aa12-e6e0-4b2c-d2d0-3cfef35feaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas\n",
        "import torch\n",
        "\n",
        "quora_questions_dataset = pandas.read_csv(\"train.csv\", nrows=5000)\n",
        "quora_questions_dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  ...                                          question2 is_duplicate\n",
              "0   0     1  ...  What is the step by step guide to invest in sh...            0\n",
              "1   1     3  ...  What would happen if the Indian government sto...            0\n",
              "2   2     5  ...  How can Internet speed be increased by hacking...            0\n",
              "3   3     7  ...  Find the remainder when [math]23^{24}[/math] i...            0\n",
              "4   4     9  ...            Which fish would survive in salt water?            0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayWHY8UuVf0T",
        "outputId": "c02c166e-e322-4861-cfc4-118c58a5bb87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "quora_questions_dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            5000 non-null   int64 \n",
            " 1   qid1          5000 non-null   int64 \n",
            " 2   qid2          5000 non-null   int64 \n",
            " 3   question1     5000 non-null   object\n",
            " 4   question2     5000 non-null   object\n",
            " 5   is_duplicate  5000 non-null   int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 234.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYXSRk60AH2y"
      },
      "source": [
        "There are 3 entries with NaN value - causes problem downstream - remove these entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwU8g4UNL_j9"
      },
      "source": [
        "proc_dataset = quora_questions_dataset.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7GxSVErMHL4",
        "outputId": "173868ce-46c0-49b0-b232-5f1f2db6252e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "proc_dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5000 entries, 0 to 4999\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   id            5000 non-null   int64 \n",
            " 1   qid1          5000 non-null   int64 \n",
            " 2   qid2          5000 non-null   int64 \n",
            " 3   question1     5000 non-null   object\n",
            " 4   question2     5000 non-null   object\n",
            " 5   is_duplicate  5000 non-null   int64 \n",
            "dtypes: int64(4), object(2)\n",
            "memory usage: 273.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuqkXFLGyjb5"
      },
      "source": [
        "Save the labels in proc_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyGAN5_v7r6_"
      },
      "source": [
        "proc_labels = proc_dataset.is_duplicate.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfclP_tb0KUz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXQCzsvaXLmC"
      },
      "source": [
        "###Step 2: Tokenize the input data\n",
        "\n",
        "Use BERT tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP8ooeK7WPqc"
      },
      "source": [
        "Tokenize questions, get summary stats on the length of tokens per question so we can determine model parameters (sequence length, etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C09waxyzX8Ps",
        "outputId": "1e0dc963-db69-4bcd-c7e5-c15a52f4973e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7U3vZnqWYjt"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "#from transformers import BertTokenizer\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugycP3cUYGTa"
      },
      "source": [
        "explore the tokenizer a bit  (we can also change the tokenizers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLqbav-zYKh3",
        "outputId": "28986e34-a3ff-4a2a-e03e-c6101946a555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Original: {quora_questions_dataset['question1'][0]}\")\n",
        "print(f\"Tokenized: {tokenizer.tokenize(quora_questions_dataset['question1'][0])}\")\n",
        "print(f\"Token IDs: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(quora_questions_dataset['question1'][0]))}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: What is the step by step guide to invest in share market in india?\n",
            "Tokenized: ['what', 'is', 'the', 'step', 'by', 'step', 'guide', 'to', 'invest', 'in', 'share', 'market', 'in', 'india', '?']\n",
            "Token IDs: [2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh6GR35QYU6G",
        "outputId": "76e1e05c-a9c2-418a-f3b9-14aa8f23d5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(f\"Original: {quora_questions_dataset['question2'][0]}\")\n",
        "print(f\"Tokenized: {tokenizer.encode(quora_questions_dataset['question2'][0])}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original: What is the step by step guide to invest in share market?\n",
            "Tokenized: [101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1029, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLD5riRPYcYH"
      },
      "source": [
        "convert tokens to words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VIj74HOYame",
        "outputId": "184e2dc4-1e10-4732-ea87-88f4a3275b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.decode([101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1029, 102])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] what is the step by step guide to invest in share market? [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPD-HIdzZPoH"
      },
      "source": [
        "###length of questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulzV4oNoWy2N"
      },
      "source": [
        "We need to find the maximum length of questions (if we use wordpair or bytepair tokenizer, etc., legnth of tokens / question can be longer than words per question) \n",
        "\n",
        "following needs a tokenizer  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poFlKMkRW9Vs",
        "outputId": "a992efb5-b42e-4ce3-c42e-268a01926ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n",
        "quora_questions_dataset[\"question1_length\"] = quora_questions_dataset[\"question1\"].progress_apply(lambda question: \n",
        "                                                                                      len(tokenizer.tokenize(question)))\n",
        "quora_questions_dataset[\"question2_length\"] = quora_questions_dataset[\"question2\"].progress_apply(lambda question: \n",
        "                                                                                      len(tokenizer.tokenize(question)))\n",
        "quora_questions_dataset[\"joint_length\"] = quora_questions_dataset[\"question1_length\"] + quora_questions_dataset[\"question2_length\"]\n",
        "print('\\n')\n",
        "print (\"max length of questions in the quora dataset *** \")\n",
        "quora_questions_dataset[\"joint_length\"].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:00<00:00, 5072.51it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 5043.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "max length of questions in the quora dataset *** \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "310"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMwpFwiGqPfA"
      },
      "source": [
        "THE FOLLOWING EXPERIMENTATION WITH TOKENIZER\n",
        "\n",
        "Segment label - sentence 1 is segment A, sentence 2 is segment B\n",
        "and put the label\n",
        "\n",
        "check for first SEP token - upto that pont it is segment A."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVCiTnY6qKjW",
        "outputId": "c4f2b080-7fb3-4eaf-8930-275aa178e9c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "num_rows = quora_questions_dataset.shape[0]\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "encoded_dict ={}\n",
        "#for i in range(num_rows):\n",
        "for i in range (5):\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                    quora_questions_dataset['question1'][i],\n",
        "                    quora_questions_dataset['question2'][i],\n",
        "                    add_special_tokens = True,\n",
        "                    truncation=True,\n",
        "                    max_length = 512,\n",
        "                    pad_to_max_length = True,\n",
        "                    return_token_type_ids = True,\n",
        "                    return_attention_mask = True,\n",
        "  )\n",
        "  print (encoded_dict[\"input_ids\"])\n",
        "  print (encoded_dict[\"token_type_ids\"])\n",
        "  print (\"reverse_sentence  \", tokenizer.decode(encoded_dict['input_ids']))\n",
        "  # return_tensors = 'pt'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029, 102, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "reverse_sentence   [CLS] what is the step by step guide to invest in share market in india? [SEP] what is the step by step guide to invest in share market? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[101, 2054, 2003, 1996, 2466, 1997, 12849, 10606, 16506, 1006, 12849, 2232, 1011, 1045, 1011, 2053, 2953, 1007, 6323, 1029, 102, 2054, 2052, 4148, 2065, 1996, 2796, 2231, 10312, 1996, 12849, 10606, 16506, 1006, 12849, 2232, 1011, 1045, 1011, 2053, 2953, 1007, 6323, 2067, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "reverse_sentence   [CLS] what is the story of kohinoor ( koh - i - noor ) diamond? [SEP] what would happen if the indian government stole the kohinoor ( koh - i - noor ) diamond back? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[101, 2129, 2064, 1045, 3623, 1996, 3177, 1997, 2026, 4274, 4434, 2096, 2478, 1037, 21210, 2078, 1029, 102, 2129, 2064, 4274, 3177, 2022, 3445, 2011, 23707, 2083, 1040, 3619, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "reverse_sentence   [CLS] how can i increase the speed of my internet connection while using a vpn? [SEP] how can internet speed be increased by hacking through dns? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[101, 2339, 2572, 1045, 10597, 2200, 9479, 1029, 2129, 2064, 1045, 9611, 2009, 1029, 102, 2424, 1996, 6893, 2043, 1031, 8785, 1033, 2603, 1034, 1063, 2484, 1065, 1031, 1013, 8785, 1033, 2003, 4055, 2011, 2484, 1010, 2603, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "reverse_sentence   [CLS] why am i mentally very lonely? how can i solve it? [SEP] find the remainder when [ math ] 23 ^ { 24 } [ / math ] is divided by 24, 23? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[101, 2029, 2028, 21969, 1999, 2300, 21864, 2243, 2135, 5699, 1010, 5474, 1010, 24481, 1998, 6351, 4487, 15772, 1029, 102, 2029, 3869, 2052, 5788, 1999, 5474, 2300, 1029, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "reverse_sentence   [CLS] which one dissolve in water quikly sugar, salt, methane and carbon di oxide? [SEP] which fish would survive in salt water? [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqpg_Mpvyz6U",
        "outputId": "5a114d9a-b30e-4873-e012-d117aa6bb050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "for i in range (5):\n",
        "  # print (\"input tokenized : \")\n",
        "  #combined_text = quora_questions_dataset['question1'][i] + \"[SEP]\" + quora_questions_dataset['question2'][i] \n",
        "  #print (\"input tokenized : \", tokenizer.tokenize(quora_questions_dataset['question1'][i], quora_questions_dataset['question2'][i] ))\n",
        "  encoded_dict = tokenizer(quora_questions_dataset['question1'][i], quora_questions_dataset['question2'][i])\n",
        "  print (encoded_dict)\n",
        "  print (\"reverse_sentence  \", encoded_dict['token_type_ids'])\n",
        "  print (\"reverse_sentence  \", tokenizer.decode(encoded_dict['input_ids']))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1999, 2634, 1029, 102, 2054, 2003, 1996, 3357, 2011, 3357, 5009, 2000, 15697, 1999, 3745, 3006, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "reverse_sentence   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "reverse_sentence   [CLS] what is the step by step guide to invest in share market in india? [SEP] what is the step by step guide to invest in share market? [SEP]\n",
            "{'input_ids': [101, 2054, 2003, 1996, 2466, 1997, 12849, 10606, 16506, 1006, 12849, 2232, 1011, 1045, 1011, 2053, 2953, 1007, 6323, 1029, 102, 2054, 2052, 4148, 2065, 1996, 2796, 2231, 10312, 1996, 12849, 10606, 16506, 1006, 12849, 2232, 1011, 1045, 1011, 2053, 2953, 1007, 6323, 2067, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "reverse_sentence   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "reverse_sentence   [CLS] what is the story of kohinoor ( koh - i - noor ) diamond? [SEP] what would happen if the indian government stole the kohinoor ( koh - i - noor ) diamond back? [SEP]\n",
            "{'input_ids': [101, 2129, 2064, 1045, 3623, 1996, 3177, 1997, 2026, 4274, 4434, 2096, 2478, 1037, 21210, 2078, 1029, 102, 2129, 2064, 4274, 3177, 2022, 3445, 2011, 23707, 2083, 1040, 3619, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "reverse_sentence   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "reverse_sentence   [CLS] how can i increase the speed of my internet connection while using a vpn? [SEP] how can internet speed be increased by hacking through dns? [SEP]\n",
            "{'input_ids': [101, 2339, 2572, 1045, 10597, 2200, 9479, 1029, 2129, 2064, 1045, 9611, 2009, 1029, 102, 2424, 1996, 6893, 2043, 1031, 8785, 1033, 2603, 1034, 1063, 2484, 1065, 1031, 1013, 8785, 1033, 2003, 4055, 2011, 2484, 1010, 2603, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "reverse_sentence   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "reverse_sentence   [CLS] why am i mentally very lonely? how can i solve it? [SEP] find the remainder when [ math ] 23 ^ { 24 } [ / math ] is divided by 24, 23? [SEP]\n",
            "{'input_ids': [101, 2029, 2028, 21969, 1999, 2300, 21864, 2243, 2135, 5699, 1010, 5474, 1010, 24481, 1998, 6351, 4487, 15772, 1029, 102, 2029, 3869, 2052, 5788, 1999, 5474, 2300, 1029, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "reverse_sentence   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "reverse_sentence   [CLS] which one dissolve in water quikly sugar, salt, methane and carbon di oxide? [SEP] which fish would survive in salt water? [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z32TWtl2S4b"
      },
      "source": [
        "Covert input dataset into tokenized input ids (for fine-tuning the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l8JO7DL3iSk"
      },
      "source": [
        "import torch # move to a different cell\n",
        "num_rows = proc_dataset.shape[0]\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "token_type_ids = []\n",
        "temp_labels = []\n",
        "for row in proc_dataset.itertuples():\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                    row.question1,\n",
        "                    row.question2,\n",
        "                    add_special_tokens = True,\n",
        "                    truncation=False,\n",
        "                    max_length = 510,\n",
        "                    padding = 'max_length',\n",
        "                    return_token_type_ids = True,\n",
        "                    return_attention_mask = True,\n",
        "                    return_tensors = 'pt'\n",
        "  )\n",
        "  # Add the encoded sentence to the list.    \n",
        "  input_ids.append(encoded_dict['input_ids'])\n",
        "  attention_masks.append(encoded_dict['attention_mask'])\n",
        "  token_type_ids.append (encoded_dict[\"token_type_ids\"])\n",
        "  # Token type ids to separate the two sentences\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "token_type_ids = torch.cat(token_type_ids, dim=0)\n",
        "labels = torch.Tensor(proc_labels).type(torch.LongTensor)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMjfgcT_FnMW"
      },
      "source": [
        "###Step 2.1 Split the Dataset into Training and Validation sets\n",
        "\n",
        "and store the dataset in pytorch tensor format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQhV1IvFuNz",
        "outputId": "03acdf52-c9f9-4088-b661-10377afdba85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids,  attention_masks,  token_type_ids, labels )\n",
        "\n",
        "train_val_split = 0.9\n",
        "train_size = int(train_val_split * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4,500 training samples\n",
            "  500 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_wlm_Wv2nDX"
      },
      "source": [
        "Save the dataset for use in the future (for different experiments with the fine tuning of the model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJHvLnsEsL6_"
      },
      "source": [
        "torch.save (dataset, \"./dataset.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI2TomN6Uxv7"
      },
      "source": [
        "##Step 2.2 Load Saved Dataset \n",
        "\n",
        "For additional experiments with fine-tuning, we can simply load the preprocessd dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzJ-zKAwTxCO",
        "outputId": "a6cb7e10-40ed-4c01-8541-1a2dea00d13e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "data_test_xx = torch.load(\"./dataset.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-14f0622fe78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_test_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dataset.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6NAHPbqU2j9",
        "outputId": "a4aafdee-3759-4510-8757-87369c6247dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# ******\n",
        "# USE WITH SAVED dataset\n",
        "# ********\n",
        "\n",
        "#dataset = TensorDataset(input_ids,  attention_masks,  token_type_ids, labels )\n",
        "dataset = torch.load(\"./dataset.pt\")\n",
        "\n",
        "train_val_split = 0.9\n",
        "train_size = int(train_val_split * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "363,858 training samples\n",
            "40,429 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK5nBP6a2v8p"
      },
      "source": [
        "Split the data into training / validation steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6FymJJjOfJM"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg6mHoBZamcP"
      },
      "source": [
        "### Step 3: Fine-tune the Model\n",
        "\n",
        "Fine tune the basic BertForSequenceClassification model using the QQP dataset\n",
        "\n",
        "More information on model parameters at:\n",
        "\n",
        "https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "\n",
        "More info on model output\n",
        "\n",
        "https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "\n",
        "More information on finetuning\n",
        "\n",
        "https://huggingface.co/transformers/training.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5uoowNaXkBI"
      },
      "source": [
        "During training, after one epoch, the GPU would run out of memory. So the model was saved after one epoch, loaded again and trained for the 2nd epoch and so on.\n",
        "\n",
        "For the 1st epoch, use BertForTokenClassification.from_pretrained('bert-base-uncased'  -- the base model.\n",
        "\n",
        "For subsequent epochs, use the saved model from the previous epoch.\n",
        "\n",
        "-- will investigate the use of pytorch dataset to avoid this memory problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h5RVofuOogC",
        "outputId": "ca43d45e-d791-4669-829a-8dac0d942fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    './models_saved_qqp_oct9C/'\n",
        ", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YErypmKOuVA",
        "outputId": "f575e58d-b5c4-4879-aa91-d56ac10b3e3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (4, 768)\n",
            "classifier.bias                                                 (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUsSKu2kO02n"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMpx5KHEO1fv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 2  # using a model that was already trained 1 epoch.\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOld-iG7O5pE"
      },
      "source": [
        "Traing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytivu2ciO7VH"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXJjtT9GPAfH"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNvCdPIrw3dY",
        "outputId": "6ee6e7c4-2181-40c5-fe62-293f6adbec1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4bOSjLJPFO9",
        "outputId": "79448c04-928a-4754-fdc2-04dc5736793b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "loss_values = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. \n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 500 batches.\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU \n",
        "  \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        " \n",
        "        \n",
        "        # Clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        " \n",
        "        outputs = model(b_input_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             token_type_ids=b_token_type_ids,\n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "   \n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    loss_values.append(avg_train_loss)\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        " \n",
        "        # Tell  pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "   \n",
        "            val_outputs = model(b_input_ids, \n",
        "                                attention_mask=b_input_mask, \n",
        "                                token_type_ids=b_token_type_ids, \n",
        "                                labels = b_labels)\n",
        "                                   \n",
        "        loss = val_outputs[0]\n",
        "        logits = val_outputs[1]          \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch   500  of  22,742.    Elapsed: 0:04:06.\n",
            "  Batch 1,000  of  22,742.    Elapsed: 0:08:13.\n",
            "  Batch 1,500  of  22,742.    Elapsed: 0:12:20.\n",
            "  Batch 2,000  of  22,742.    Elapsed: 0:16:27.\n",
            "  Batch 2,500  of  22,742.    Elapsed: 0:20:34.\n",
            "  Batch 3,000  of  22,742.    Elapsed: 0:24:41.\n",
            "  Batch 3,500  of  22,742.    Elapsed: 0:28:48.\n",
            "  Batch 4,000  of  22,742.    Elapsed: 0:32:55.\n",
            "  Batch 4,500  of  22,742.    Elapsed: 0:37:02.\n",
            "  Batch 5,000  of  22,742.    Elapsed: 0:41:09.\n",
            "  Batch 5,500  of  22,742.    Elapsed: 0:45:17.\n",
            "  Batch 6,000  of  22,742.    Elapsed: 0:49:23.\n",
            "  Batch 6,500  of  22,742.    Elapsed: 0:53:30.\n",
            "  Batch 7,000  of  22,742.    Elapsed: 0:57:37.\n",
            "  Batch 7,500  of  22,742.    Elapsed: 1:01:44.\n",
            "  Batch 8,000  of  22,742.    Elapsed: 1:05:50.\n",
            "  Batch 8,500  of  22,742.    Elapsed: 1:09:57.\n",
            "  Batch 9,000  of  22,742.    Elapsed: 1:14:04.\n",
            "  Batch 9,500  of  22,742.    Elapsed: 1:18:10.\n",
            "  Batch 10,000  of  22,742.    Elapsed: 1:22:17.\n",
            "  Batch 10,500  of  22,742.    Elapsed: 1:26:23.\n",
            "  Batch 11,000  of  22,742.    Elapsed: 1:30:29.\n",
            "  Batch 11,500  of  22,742.    Elapsed: 1:34:36.\n",
            "  Batch 12,000  of  22,742.    Elapsed: 1:38:43.\n",
            "  Batch 12,500  of  22,742.    Elapsed: 1:42:49.\n",
            "  Batch 13,000  of  22,742.    Elapsed: 1:46:56.\n",
            "  Batch 13,500  of  22,742.    Elapsed: 1:51:04.\n",
            "  Batch 14,000  of  22,742.    Elapsed: 1:55:10.\n",
            "  Batch 14,500  of  22,742.    Elapsed: 1:59:17.\n",
            "  Batch 15,000  of  22,742.    Elapsed: 2:03:24.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jezMrZGd4uLB",
        "outputId": "6577bb0d-e9f0-477e-e4db-5c363c59f418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(loss_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OtXzq_kI9EN",
        "outputId": "887a195c-ad2d-407c-9780-925bb721c758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss_values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21056184215684579]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqNxT8-xWLEG",
        "outputId": "2d9147fd-9299-422f-aa88-0461848b43e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luE2iCL-1-RW"
      },
      "source": [
        "save the model (3rd trial run on Oct 8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HbxEQg716DA",
        "outputId": "92c8645d-b9c9-4814-d84a-fcdcc17a6bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_dir = './models_saved_qqp_oct9Final/'\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "model.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./models_saved_qqp_oct9C/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYfuL_Dr5aY1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}